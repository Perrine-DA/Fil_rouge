{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMXBwRxfd9gi"
   },
   "source": [
    "# Projet Energie : préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy04GIKTd9go"
   },
   "source": [
    "1. Première exploration et description des données brutes issues de la source de données\n",
    "    - quelques lignes exemples      \n",
    "    - description\n",
    "    - types\n",
    "2. Data profiling : analyse de la qualité des données\n",
    "3. Traitement des données. \n",
    "4. Ajout de données complémentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IE49EIxLd9gp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XJ-H2-HAJkC4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "csvPathCommun = '/content/eco2mix-regional-cons-def.csv'\n",
    "csvPathlocal = 'eco2mix-regional-cons-def.csv'\n",
    "\n",
    "df = pd.read_csv(csvPathlocal, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "RWselxKrd9gs",
    "outputId": "8ac79fff-6282-4c6c-e049-16b530aabb57"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code INSEE région</th>\n",
       "      <th>Région</th>\n",
       "      <th>Nature</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heure</th>\n",
       "      <th>Date - Heure</th>\n",
       "      <th>Consommation (MW)</th>\n",
       "      <th>Thermique (MW)</th>\n",
       "      <th>Nucléaire (MW)</th>\n",
       "      <th>Eolien (MW)</th>\n",
       "      <th>...</th>\n",
       "      <th>TCH Nucléaire (%)</th>\n",
       "      <th>TCO Eolien (%)</th>\n",
       "      <th>TCH Eolien (%)</th>\n",
       "      <th>TCO Solaire (%)</th>\n",
       "      <th>TCH Solaire (%)</th>\n",
       "      <th>TCO Hydraulique (%)</th>\n",
       "      <th>TCH Hydraulique (%)</th>\n",
       "      <th>TCO Bioénergies (%)</th>\n",
       "      <th>TCH Bioénergies (%)</th>\n",
       "      <th>Column 30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>Bourgogne-Franche-Comté</td>\n",
       "      <td>Données définitives</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2013-01-01T00:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Normandie</td>\n",
       "      <td>Données définitives</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2013-01-01T00:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Hauts-de-France</td>\n",
       "      <td>Données définitives</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2013-01-01T00:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Bretagne</td>\n",
       "      <td>Données définitives</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2013-01-01T00:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Île-de-France</td>\n",
       "      <td>Données définitives</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2013-01-01T00:00:00+01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code INSEE région                   Région               Nature  \\\n",
       "0                 27  Bourgogne-Franche-Comté  Données définitives   \n",
       "1                 28                Normandie  Données définitives   \n",
       "2                 32          Hauts-de-France  Données définitives   \n",
       "3                 53                 Bretagne  Données définitives   \n",
       "4                 11            Île-de-France  Données définitives   \n",
       "\n",
       "         Date  Heure               Date - Heure  Consommation (MW)  \\\n",
       "0  2013-01-01  00:00  2013-01-01T00:00:00+01:00                NaN   \n",
       "1  2013-01-01  00:00  2013-01-01T00:00:00+01:00                NaN   \n",
       "2  2013-01-01  00:00  2013-01-01T00:00:00+01:00                NaN   \n",
       "3  2013-01-01  00:00  2013-01-01T00:00:00+01:00                NaN   \n",
       "4  2013-01-01  00:00  2013-01-01T00:00:00+01:00                NaN   \n",
       "\n",
       "   Thermique (MW)  Nucléaire (MW)  Eolien (MW)  ...  TCH Nucléaire (%)  \\\n",
       "0             NaN             NaN          NaN  ...                NaN   \n",
       "1             NaN             NaN          NaN  ...                NaN   \n",
       "2             NaN             NaN          NaN  ...                NaN   \n",
       "3             NaN             NaN          NaN  ...                NaN   \n",
       "4             NaN             NaN          NaN  ...                NaN   \n",
       "\n",
       "   TCO Eolien (%)  TCH Eolien (%)  TCO Solaire (%)  TCH Solaire (%)  \\\n",
       "0             NaN             NaN              NaN              NaN   \n",
       "1             NaN             NaN              NaN              NaN   \n",
       "2             NaN             NaN              NaN              NaN   \n",
       "3             NaN             NaN              NaN              NaN   \n",
       "4             NaN             NaN              NaN              NaN   \n",
       "\n",
       "   TCO Hydraulique (%)  TCH Hydraulique (%)  TCO Bioénergies (%)  \\\n",
       "0                  NaN                  NaN                  NaN   \n",
       "1                  NaN                  NaN                  NaN   \n",
       "2                  NaN                  NaN                  NaN   \n",
       "3                  NaN                  NaN                  NaN   \n",
       "4                  NaN                  NaN                  NaN   \n",
       "\n",
       "   TCH Bioénergies (%)  Column 30  \n",
       "0                  NaN        NaN  \n",
       "1                  NaN        NaN  \n",
       "2                  NaN        NaN  \n",
       "3                  NaN        NaN  \n",
       "4                  NaN        NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0A1lXZELRpR",
    "outputId": "7ccb7e2a-01d1-4283-d2db-f6e82be05969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1683072 entries, 0 to 1683071\n",
      "Data columns (total 32 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   Code INSEE région    1683072 non-null  int64  \n",
      " 1   Région               1683072 non-null  object \n",
      " 2   Nature               1683072 non-null  object \n",
      " 3   Date                 1683072 non-null  object \n",
      " 4   Heure                1683072 non-null  object \n",
      " 5   Date - Heure         1683072 non-null  object \n",
      " 6   Consommation (MW)    1683060 non-null  float64\n",
      " 7   Thermique (MW)       1683060 non-null  float64\n",
      " 8   Nucléaire (MW)       981785 non-null   float64\n",
      " 9   Eolien (MW)          1682964 non-null  float64\n",
      " 10  Solaire (MW)         1683060 non-null  float64\n",
      " 11  Hydraulique (MW)     1683060 non-null  float64\n",
      " 12  Pompage (MW)         946745 non-null   float64\n",
      " 13  Bioénergies (MW)     1683060 non-null  float64\n",
      " 14  Ech. physiques (MW)  1683060 non-null  float64\n",
      " 15  Stockage batterie    0 non-null        float64\n",
      " 16  Déstockage batterie  0 non-null        float64\n",
      " 17  Eolien terrestre     0 non-null        float64\n",
      " 18  Eolien offshore      0 non-null        float64\n",
      " 19  TCO Thermique (%)    210816 non-null   float64\n",
      " 20  TCH Thermique (%)    210816 non-null   float64\n",
      " 21  TCO Nucléaire (%)    122976 non-null   float64\n",
      " 22  TCH Nucléaire (%)    122976 non-null   float64\n",
      " 23  TCO Eolien (%)       210816 non-null   float64\n",
      " 24  TCH Eolien (%)       210816 non-null   float64\n",
      " 25  TCO Solaire (%)      210816 non-null   float64\n",
      " 26  TCH Solaire (%)      210816 non-null   float64\n",
      " 27  TCO Hydraulique (%)  210816 non-null   float64\n",
      " 28  TCH Hydraulique (%)  210816 non-null   float64\n",
      " 29  TCO Bioénergies (%)  210816 non-null   float64\n",
      " 30  TCH Bioénergies (%)  210816 non-null   float64\n",
      " 31  Column 30            0 non-null        float64\n",
      "dtypes: float64(26), int64(1), object(5)\n",
      "memory usage: 410.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Préparation des données issues de la source principale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koMutRPad9gu"
   },
   "source": [
    "***Date et heure***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf7sl48qd9gv"
   },
   "source": [
    "Création d'une colonne type Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x-_9CZrMs70V"
   },
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['Date - Heure'], format=\"%Y-%m-%dT%H:%M:%S%z\", utc=True ).dt.tz_convert('Europe/Berlin').dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7Rhh9nxNEh6",
    "outputId": "5457dba0-799e-4b8f-8955-9c89e82c1b68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2013-01-01\n",
       "1   2013-01-01\n",
       "2   2013-01-01\n",
       "3   2013-01-01\n",
       "4   2013-01-01\n",
       "Name: datetime, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversion du texte representant une date en objet type datetime afin de travailler plus efficacement à l'aide des methodes de datetime\n",
    "# ne fonctionne plus ... df['datetime'] = pd.to_datetime(df['Date - Heure'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "#df['datetime'] = df['datetime'].astype('datetime64[ns, UTC+01:00]')\n",
    "df['datetime'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmeZ55_Wd9gw"
   },
   "source": [
    "**Creation des colonnes indicatrices temporelles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_mois'] = df['datetime'].dt.month\n",
    "df['annee'] = df['datetime'].dt.year\n",
    "df['mois_sin'] = np.sin(df['datetime'].dt.month * 2 * np.pi / 12 )\n",
    "df['mois_cos'] = np.cos(df['datetime'].dt.month * 2 * np.pi / 12 )\n",
    "df['jour_sin'] = np.sin(df['datetime'].dt.day * 2 * np.pi / 31 )\n",
    "df['jour_cos'] = np.cos(df['datetime'].dt.day * 2 * np.pi / 31 )\n",
    "df['saison'] = df['num_mois'].\\\n",
    "replace(to_replace=[[1,2,3,12], [4,5],[6,7,8],[9,10,11]], value=[0, 1, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lI2kbHjHd9gx"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Date','Heure','Date - Heure'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-s0KMLTd9gx"
   },
   "source": [
    "***Colonne NATURE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3UgdiINd9gy",
    "outputId": "c706ab50-bfbd-4296-8ba7-3a5ad090e36e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nature\n",
       "Données définitives    1683072\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Nature.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdHD-h_Xd9gy"
   },
   "source": [
    "Colonne 'Nature' : On pourrait travailler que sur les données définitives c'est à dire jusqu'à fin 2020, et supprimer cette colonne. Ou alors simplement supprimer cette colonne en faisant confiance au données à partir de 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rNoMdcWzd9gy"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Nature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RQe2Yupd9gy"
   },
   "source": [
    "***Colonne 'column30'*** ne contient rien : supprimée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idpFS5gVd9gz",
    "outputId": "b190479f-42b8-4b6e-92e2-d340a3270f3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Column 30'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "m2ISOsZAd9gz"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Column 30'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cq5jZpGd9gz"
   },
   "source": [
    "***QUALITE DES DONNEES***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwRcwYqAd9gz"
   },
   "source": [
    "***Valeurs manquantes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kiitjBRC8UPr",
    "outputId": "7aaa0246-405a-4efd-9eee-9fe8775d0135"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code INSEE région            0\n",
       "Région                       0\n",
       "Consommation (MW)           12\n",
       "Thermique (MW)              12\n",
       "Nucléaire (MW)          701287\n",
       "Eolien (MW)                108\n",
       "Solaire (MW)                12\n",
       "Hydraulique (MW)            12\n",
       "Pompage (MW)            736327\n",
       "Bioénergies (MW)            12\n",
       "Ech. physiques (MW)         12\n",
       "Stockage batterie      1683072\n",
       "Déstockage batterie    1683072\n",
       "Eolien terrestre       1683072\n",
       "Eolien offshore        1683072\n",
       "TCO Thermique (%)      1472256\n",
       "TCH Thermique (%)      1472256\n",
       "TCO Nucléaire (%)      1560096\n",
       "TCH Nucléaire (%)      1560096\n",
       "TCO Eolien (%)         1472256\n",
       "TCH Eolien (%)         1472256\n",
       "TCO Solaire (%)        1472256\n",
       "TCH Solaire (%)        1472256\n",
       "TCO Hydraulique (%)    1472256\n",
       "TCH Hydraulique (%)    1472256\n",
       "TCO Bioénergies (%)    1472256\n",
       "TCH Bioénergies (%)    1472256\n",
       "datetime                     0\n",
       "num_mois                     0\n",
       "annee                        0\n",
       "mois_sin                     0\n",
       "mois_cos                     0\n",
       "jour_sin                     0\n",
       "jour_cos                     0\n",
       "saison                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Characters such as empty strings '' or numpy.inf are not considered NA values (unless you set pd.options.mode.use_inf_as_na = True)\n",
    "pd.options.mode.use_inf_as_na = True # pour qu'il considère une chaine de caractère vide comme une donnée manquante.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klGzTwOnd9g0",
    "outputId": "f243653c-7974-4845-a125-a98b44c4222e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The feature Nucléaire (MW) contains too many missing values(41.67%) Try to fix it !\n",
      "\n",
      "The feature Pompage (MW) contains too many missing values(43.75%) Try to fix it !\n",
      "\n",
      "The feature Stockage batterie contains too many missing values(100.00%) Try to fix it !\n",
      "\n",
      "The feature Déstockage batterie contains too many missing values(100.00%) Try to fix it !\n",
      "\n",
      "The feature Eolien terrestre contains too many missing values(100.00%) Try to fix it !\n",
      "\n",
      "The feature Eolien offshore contains too many missing values(100.00%) Try to fix it !\n",
      "\n",
      "The feature TCO Thermique (%) contains too many missing values(87.47%) Try to fix it !\n",
      "\n",
      "The feature TCH Thermique (%) contains too many missing values(87.47%) Try to fix it !\n",
      "\n",
      "The feature TCO Nucléaire (%) contains too many missing values(92.69%) Try to fix it !\n",
      "\n",
      "The feature TCH Nucléaire (%) contains too many missing values(92.69%) Try to fix it !\n",
      "\n",
      "The feature TCO Eolien (%) contains too many missing values(87.47%) Try to fix it !\n",
      "\n",
      "The feature TCH Eolien (%) contains too many missing values(87.47%) Try to fix it !\n",
      "\n",
      "The feature TCO Solaire (%) contains too many missing values(87.47%) Try to fix it !\n",
      "\n",
      "The feature TCH Solaire (%) contains too many missing values(87.47%) Try to fix it !\n",
      "\n",
      "The feature TCO Hydraulique (%) contains too many missing values(87.47%) Try to fix it !\n",
      "\n",
      "The feature TCH Hydraulique (%) contains too many missing values(87.47%) Try to fix it !\n",
      "\n",
      "The feature TCO Bioénergies (%) contains too many missing values(87.47%) Try to fix it !\n",
      "\n",
      "The feature TCH Bioénergies (%) contains too many missing values(87.47%) Try to fix it !\n"
     ]
    }
   ],
   "source": [
    "def alerts(df, thresh_na = 0.1):\n",
    "    for col in df.columns:\n",
    "        missingValuesRate = 100 * df[col].isna().sum()/len(df)\n",
    "        if (missingValuesRate) > thresh_na:\n",
    "            print('\\nThe feature {} contains too many missing values({:.2f}%) Try to fix it !'\\\n",
    "                  .format(col,missingValuesRate))\n",
    "\n",
    "alerts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qFBhNRJd9g0"
   },
   "source": [
    "***Analyse des valeurs manquantes sur les colonnes TCO XXX et TCH XXX***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fQYQCC6ed9g0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select columns by regular expression\n",
    "columns_TC = df.filter(regex='^TC.*', axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xl4V6TX3d9g0",
    "outputId": "7ab6e7ff-a4a2-4e64-c1f0-338d96953729",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCO Thermique (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n",
      "TCH Thermique (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n",
      "TCO Nucléaire (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019 2020]\n",
      "TCH Nucléaire (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019 2020]\n",
      "TCO Eolien (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n",
      "TCH Eolien (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n",
      "TCO Solaire (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n",
      "TCH Solaire (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n",
      "TCO Hydraulique (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n",
      "TCH Hydraulique (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n",
      "TCO Bioénergies (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n",
      "TCH Bioénergies (%) , années avec données manquantes :  [2013 2014 2015 2016 2017 2018 2019]\n"
     ]
    }
   ],
   "source": [
    "for tc_colonne in columns_TC:\n",
    "    print(tc_colonne, ', années avec données manquantes : ', df[df[tc_colonne].isna()]['datetime'].dt.year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzIUpG_sd9g0",
    "outputId": "8670ee61-8404-4ae4-ef21-0b071dbf38f7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The feature Nucléaire (MW) contains too many missing values(41.67%) Try to fix it !\n",
      "\n",
      "The feature Pompage (MW) contains too many missing values(41.67%) Try to fix it !\n",
      "\n",
      "The feature Stockage batterie contains too many missing values(100.00%) Try to fix it !\n",
      "\n",
      "The feature Déstockage batterie contains too many missing values(100.00%) Try to fix it !\n",
      "\n",
      "The feature Eolien terrestre contains too many missing values(100.00%) Try to fix it !\n",
      "\n",
      "The feature Eolien offshore contains too many missing values(100.00%) Try to fix it !\n",
      "\n",
      "The feature TCO Nucléaire (%) contains too many missing values(41.67%) Try to fix it !\n",
      "\n",
      "The feature TCH Nucléaire (%) contains too many missing values(41.67%) Try to fix it !\n"
     ]
    }
   ],
   "source": [
    "alerts( df[df['datetime'].dt.year == 2020] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrpl9J5-d9g0"
   },
   "source": [
    "***Suppression des colonnes sans aucune données de production***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "I0hS4Vekd9g1"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Stockage batterie', 'Déstockage batterie',\\\n",
    "                      'Eolien terrestre','Eolien offshore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25ElF3SGd9g1"
   },
   "source": [
    "***Quelles sont les lignes où la consommation n'est pas renseignée ?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8h0vsdGd9g1",
    "outputId": "49bdc3b4-b1a4-4a60-ceb0-a6d0814755d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2013-01-01\n",
       "1    2013-01-01\n",
       "2    2013-01-01\n",
       "3    2013-01-01\n",
       "4    2013-01-01\n",
       "5    2013-01-01\n",
       "6    2013-01-01\n",
       "7    2013-01-01\n",
       "8    2013-01-01\n",
       "9    2013-01-01\n",
       "10   2013-01-01\n",
       "11   2013-01-01\n",
       "Name: datetime, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Consommation (MW)'].isna()].datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dPLK_Upd9g1"
   },
   "source": [
    "Suppression des 12 lignes (1er janvier 2013 à minuit) où la valeurs de consommation est absente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "i1QG8rKsd9g1"
   },
   "outputs": [],
   "source": [
    "df = df.drop(index=df[df['Consommation (MW)'].isna()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khRw4XJpd9g1"
   },
   "source": [
    "***Quelles sont les lignes où la filière nucleaire est renseignée ?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZdlOMBQd9g1",
    "outputId": "145cbfef-5771-4580-9908-4e8caff06128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Nucléaire (MW)'].notna()].datetime.dt.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIg9GnYSd9g2"
   },
   "source": [
    "***Quelles sont les lignes où la filière pompage est renseignée ?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LwVZMtfd9g2",
    "outputId": "6703e65d-d3f5-4f60-80e5-ba342618c8f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Pompage (MW)'].notna()].datetime.dt.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0BNo4Y3d9g2",
    "outputId": "0c0a8b84-a259-47da-e649-caca1c0f06af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   nan,     0.,   -13., ..., -2420., -2054., -2298.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Pompage (MW)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SL1VU38-d9g2"
   },
   "source": [
    "Remarque : la filière 'Pompage' est de l'énergie soustraite à la production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xF9L97Yd9g_"
   },
   "source": [
    "***Vérifications de la présence de doublons***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "j68BsrhVd9g_",
    "outputId": "fa4f5831-717e-41c3-bdc6-357b962831ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code INSEE région</th>\n",
       "      <th>Région</th>\n",
       "      <th>Consommation (MW)</th>\n",
       "      <th>Thermique (MW)</th>\n",
       "      <th>Nucléaire (MW)</th>\n",
       "      <th>Eolien (MW)</th>\n",
       "      <th>Solaire (MW)</th>\n",
       "      <th>Hydraulique (MW)</th>\n",
       "      <th>Pompage (MW)</th>\n",
       "      <th>Bioénergies (MW)</th>\n",
       "      <th>...</th>\n",
       "      <th>TCO Bioénergies (%)</th>\n",
       "      <th>TCH Bioénergies (%)</th>\n",
       "      <th>datetime</th>\n",
       "      <th>num_mois</th>\n",
       "      <th>annee</th>\n",
       "      <th>mois_sin</th>\n",
       "      <th>mois_cos</th>\n",
       "      <th>jour_sin</th>\n",
       "      <th>jour_cos</th>\n",
       "      <th>saison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51321</th>\n",
       "      <td>24</td>\n",
       "      <td>Centre-Val de Loire</td>\n",
       "      <td>2737.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>8613.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-03-31 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51355</th>\n",
       "      <td>24</td>\n",
       "      <td>Centre-Val de Loire</td>\n",
       "      <td>2831.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>8593.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-03-31 03:30:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Code INSEE région               Région  Consommation (MW)  \\\n",
       "51321                 24  Centre-Val de Loire             2737.0   \n",
       "51355                 24  Centre-Val de Loire             2831.0   \n",
       "\n",
       "       Thermique (MW)  Nucléaire (MW)  Eolien (MW)  Solaire (MW)  \\\n",
       "51321            85.0          8613.0        159.0           0.0   \n",
       "51355            86.0          8593.0        156.0           0.0   \n",
       "\n",
       "       Hydraulique (MW)  Pompage (MW)  Bioénergies (MW)  ...  \\\n",
       "51321              52.0           NaN              25.0  ...   \n",
       "51355              51.0           NaN              28.0  ...   \n",
       "\n",
       "       TCO Bioénergies (%)  TCH Bioénergies (%)            datetime  num_mois  \\\n",
       "51321                  NaN                  NaN 2013-03-31 03:00:00         3   \n",
       "51355                  NaN                  NaN 2013-03-31 03:30:00         3   \n",
       "\n",
       "       annee  mois_sin      mois_cos      jour_sin  jour_cos  saison  \n",
       "51321   2013       1.0  6.123234e-17 -2.449294e-16       1.0       3  \n",
       "51355   2013       1.0  6.123234e-17 -2.449294e-16       1.0       3  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013 = (df[(df.datetime.dt.year == 2013) & (df['Code INSEE région']==24)]).copy()\n",
    "df_2013.loc[df.duplicated(subset=['Code INSEE région', 'datetime'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYzYHWNkd9hA"
   },
   "source": [
    "Bizzare : il considère un doublon là où il y a 2 valeurs qui pourtant n'ont pas le meme datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7muSyUYad9hA"
   },
   "source": [
    "***Création des colonnes 'production_brute' et 'production_nette'***\n",
    "'production_brute' : Il s'agit de la production totale nationale\n",
    "'production_nette' : Il s'agit de la production brute auquel a été rajouté les échanges avec pays et les données 'Pompage' (de l'énergie consommée).   \n",
    "**Remarque :** les valeurs s'expriment en MW ; il s'agit donc d'une puissance sur le pas de temps indiqué ici 0,5h. Il faut donc multiplier par ce temps en heure pour avoir la valeur d'énergie en MWh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dT8eXm6Ed9hC",
    "outputId": "122bebca-3b03-46e0-f8c7-29cb150fffe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Code INSEE région', 'Région', 'Consommation (MW)', 'Thermique (MW)',\n",
       "       'Nucléaire (MW)', 'Eolien (MW)', 'Solaire (MW)', 'Hydraulique (MW)',\n",
       "       'Pompage (MW)', 'Bioénergies (MW)', 'Ech. physiques (MW)',\n",
       "       'TCO Thermique (%)', 'TCH Thermique (%)', 'TCO Nucléaire (%)',\n",
       "       'TCH Nucléaire (%)', 'TCO Eolien (%)', 'TCH Eolien (%)',\n",
       "       'TCO Solaire (%)', 'TCH Solaire (%)', 'TCO Hydraulique (%)',\n",
       "       'TCH Hydraulique (%)', 'TCO Bioénergies (%)', 'TCH Bioénergies (%)',\n",
       "       'datetime', 'num_mois', 'annee', 'mois_sin', 'mois_cos', 'jour_sin',\n",
       "       'jour_cos', 'saison'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "D7lPEl3Ld9hC"
   },
   "outputs": [],
   "source": [
    "def sum_prod(row, *prod_columns):\n",
    "    total_prod = 0.0\n",
    "    for prd_colon in prod_columns:\n",
    "        if (pd.notna(row[prd_colon])) :\n",
    "            total_prod += row[prd_colon]\n",
    "    return total_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9X4HSm5Ud9hC"
   },
   "outputs": [],
   "source": [
    "prod_nette_columns = ('Thermique (MW)','Nucléaire (MW)','Eolien (MW)','Solaire (MW)','Hydraulique (MW)','Bioénergies (MW)')\n",
    "df['production_nette'] = df.apply(sum_prod , args=prod_nette_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbpvXd9gd9hD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prod_brute_columns = ['Thermique (MW)','Nucléaire (MW)', 'Eolien (MW)',\\\n",
    "                 'Solaire (MW)', 'Hydraulique (MW)', 'Pompage (MW)',\\\n",
    "                 'Bioénergies (MW)', 'Ech. physiques (MW)']\n",
    "df['production_brute'] = df.apply(sum_prod , args=(prod_brute_columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Renommage en minuscule, sans espaces\n",
    "df.rename(columns={'Code INSEE région':'code_region', 'Région':'region', 'Consommation (MW)':'consommation', 'Thermique (MW)':'thermique','Nucléaire (MW)':'nucleaire', 'Eolien (MW)':'eolien', 'Solaire (MW)':'solaire', 'Hydraulique (MW)':'hydraulique','Pompage (MW)':'pompage', 'Bioénergies (MW)':'bioenergies', 'Ech. physiques (MW)':'ech.physiques','TCO Thermique (%)':'tco_thermique', 'TCH Thermique (%)':'tch_thermique', 'TCO Nucléaire (%)':'tco_nucléaire','TCH Nucléaire (%)':'tch_nucleaire', 'TCO Eolien (%)':'tco_eolien', 'TCH Eolien (%)':'tch_eolien','TCO Solaire (%)':'tco_solaire', 'TCH Solaire (%)':'tch_solaire', 'TCO Hydraulique (%)':'tco_hydraulique','TCH Hydraulique (%)':'tch_hydraulique', 'TCO Bioénergies (%)':'tco_bioenergies', 'TCH Bioénergies (%)':'tch_bioenergies'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOIXtpqCd9hD"
   },
   "source": [
    "***Colonnes définitives présentes désormais dans le Dataframe 'df'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "id": "CPft5-XEd9hD",
    "outputId": "15b40e08-e625-4b8e-f9e2-7dfa86e5bd9b"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'colonne':df.columns, 'type':df.dtypes.values}, index=range( 1, (len(df.columns) + 1) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxCW4mlKd9hD"
   },
   "source": [
    "On obtient à la fin de ce Notebook un df avec :\n",
    "\n",
    "- les colonnes sans données utiles supprimées\n",
    "- les lignes avec absences de consommations retirées\n",
    "\n",
    "- une nouvelle colonne 'datetime' type datetime64 qui exprime precisement le temps et avec laquelle on peut travailler avec n'importe quel pas de temps (regroupement, aggrégation par exemple)\n",
    "- une nouvelle colonne 'num_mois' un nombre entier précisant le mois de l'année (utile pour accès direct à la saison)\n",
    "- les colonnes 'production_brute' et 'production_nette'  \n",
    "- 'production_brute' : Il s'agit de la production totale nationale   \n",
    "- 'production_nette' : Ils s'agit de la production brute auquel a été rajouté les échanges avec pays et les données 'Pompage' (de l'énergie consommée).   \n",
    "   \n",
    "**Remarque :** les valeurs s'expriment en MW ; il s'agit donc d'une puissance sur le pas de temps indiqué ici 0,5h. Il faut donc multiplier par ce temps en heure pour avoir la valeur d'énergie en MWh.\n",
    "Remarque : Il faudra peut-être renommer les colonnes dont le nom contient des espaces : si ca pose des problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqND_3cOd9hD"
   },
   "outputs": [],
   "source": [
    "#Creation d'un fichier csv contenant le dataframe préparé\n",
    "df.to_csv(\"eco2mix-regional-prepare.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupement des données par Jour et par région"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "DUzpCh-tyAh5",
    "outputId": "d3a51270-9184-4528-a011-f9650fbfcba9"
   },
   "outputs": [],
   "source": [
    "df_jour = df.groupby(by=['code_region',pd.Grouper(key='datetime', freq='D')]).agg({'region': lambda x : x.iloc[0] , 'annee': lambda x : x.iloc[0] , 'num_mois': lambda x : x.iloc[0] ,\\\n",
    "'saison': lambda x : x.iloc[0], 'mois_sin' : lambda x : x.iloc[0], 'mois_cos': lambda x : x.iloc[0], 'jour_sin': lambda x : x.iloc[0], 'jour_cos': lambda x : x.iloc[0],\\\n",
    "'consommation': sum, 'thermique':sum, 'nucleaire':sum,'eolien':sum, 'solaire':sum, 'hydraulique':sum, 'pompage':sum, 'bioenergies':sum,'ech.physiques':sum,\\\n",
    "'tco_thermique': np.mean , 'tch_thermique': np.mean , 'tco_nucléaire': np.mean ,'tch_nucleaire': np.mean , 'tco_eolien': np.mean , 'tch_eolien': np.mean , \\\n",
    " 'tco_solaire': np.mean ,'tch_solaire': np.mean , 'tco_hydraulique': np.mean ,\\\n",
    "'tch_hydraulique': np.mean , 'tco_bioenergies': np.mean ,'tch_bioenergies': np.mean, 'production_brute' : sum, 'production_nette' : sum })\n",
    "df_jour = df_jour.reset_index()\n",
    "df_jour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ajout des températures quotidiennes régionales\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4-2cWGS8suA"
   },
   "outputs": [],
   "source": [
    "df_temperatures = pd.read_csv(\"temperature-quotidienne-regionale.csv\", parse_dates=['Date'],  sep=\";\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esx3ZTD6xqz_"
   },
   "outputs": [],
   "source": [
    "df_temperatures.drop(columns=['Région', 'ID'], inplace=True)\n",
    "df_temperatures.rename(columns={'Date':'date', 'Code INSEE région': 'code_region', 'TMin (°C)': 'TMin','TMax (°C)':'TMax','TMoy (°C)':'TMoy'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "CLjl8rE3yQMS",
    "outputId": "8073ff53-e937-418a-98bf-97ecd2b6ca8f"
   },
   "outputs": [],
   "source": [
    "df_jour_temp = df_jour.merge(right=df_temperatures, how='left',left_on=['datetime','code_region'], right_on=['date','code_region']).drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-filVJLLyXYY",
    "outputId": "9620296a-c148-4b24-9b31-63bb491e3d7c"
   },
   "outputs": [],
   "source": [
    "# on remarque que l'on a des temperatures qu'à partir de l'année 2016\n",
    "df_jour_temp[df_jour_temp.TMin.notna()]['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-iSXjPO2Idk"
   },
   "outputs": [],
   "source": [
    "#Creation d'un fichier csv contenant le dataframe préparé\n",
    "df_jour_temp.to_csv(\"eco2mix-prepare-temperatures.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMClrpJB2Unh"
   },
   "source": [
    "Ajout des données liées aux pannes de production\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ORMuIUVaimI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "indispo = pd.read_csv('defaut_production_moy_jour.csv' , parse_dates=['datetime'], index_col=0)\n",
    "indispo.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5ASNsUjaimI",
    "outputId": "59e8521e-fbf5-4836-f744-1ac2d379d02d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "indispo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Gb6BI35aimJ",
    "outputId": "3c3f76d7-7c25-4e69-e442-96bec235f9fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "indispo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Lltxx2LaimJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# afin de ne rajouter qu'une seule fois les données d'energie manquante, *\n",
    "# on choisi une région au hasard afin de lui associer la valeur d'energie manquante nationale\n",
    "\n",
    "codeRegion11Serie = pd.DataFrame({\"code_region\" : np.ones((len(indispo)),dtype='int')*11 })\n",
    "indispo_ileDeFrance = pd.concat([indispo,codeRegion11Serie], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoiYOMHTaimK",
    "outputId": "501061e0-1ad9-494b-8798-c4df54efb779",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_jour_temp_indispo = df_jour_temp.merge(right=indispo_ileDeFrance, how='left',left_on=['datetime', 'code_region'], right_on=['datetime','code_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Q4JW_ZuaimK",
    "outputId": "1179d78d-7807-4051-cd9c-b43469f2857c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_jour_temp_indispo[df_jour_temp_indispo['defaut_energie_moy_jour'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvJCykR9aimL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creation d'un fichier csv contenant le dataframe préparé\n",
    "df_jour_temp_indispo.to_csv(\"eco2mix-prepare-temperatures_indispo.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgUC_mKbb7zt"
   },
   "source": [
    "Ajout des données liées aux prix de contrats de base et contrats heures creuses - heures pleines\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiFm68Z-cLiz"
   },
   "outputs": [],
   "source": [
    "# Premier jeu de données : contrat de base\n",
    "df = pd.read_csv(\"TRV électricité inf36 BASE_2012- S2 2023.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mKi65Hjcboh"
   },
   "outputs": [],
   "source": [
    "# Création d'une colonne de prix total\n",
    "\n",
    "df[\"PART_FIXE_TTC\"] = df[\"PART_FIXE_TTC\"].apply(lambda x: x.replace(',','.').replace(',','.')).astype(\"float\")\n",
    "\n",
    "df[\"PART_VARIABLE_TTC\"] = df[\"PART_VARIABLE_TTC\"].apply(lambda x : x.replace(',','.').replace(',','.')).astype(\"float\")\n",
    "\n",
    "df[\"prix_base_moyen_ttc\"] = df[\"PART_FIXE_TTC\"] + df [\"PART_VARIABLE_TTC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwaGYASgcf39"
   },
   "outputs": [],
   "source": [
    "# Regroupement par tarif par date et calcul du prix de base moyen indépendamment de la puissance souscrite\n",
    "df_base = df.groupby([\"DATE_DEBUT\",\"DATE_FIN\"], as_index = False).agg({\"prix_base_moyen_ttc\" : \"mean\"})\n",
    "\n",
    "df_base[\"annee\"]= df_base[\"DATE_FIN\"].str[6:].astype(\"int\")\n",
    "\n",
    "df_base[\"mois\"] = df_base[\"DATE_FIN\"].str[3:5].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqetNUYAczUX"
   },
   "outputs": [],
   "source": [
    "df_base[\"DATE_DEBUT\"] = pd.to_datetime(df_base[\"DATE_DEBUT\"], format='%d/%m/%Y')\n",
    "\n",
    "df_base[\"DATE_FIN\"] = pd.to_datetime(df_base[\"DATE_FIN\"], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vk8Jjxwyc2k1"
   },
   "outputs": [],
   "source": [
    "# Création d'un tarif par jour\n",
    "def getDatetimesArray(row):\n",
    "    return pd.date_range(start=row[\"DATE_DEBUT\"],\n",
    "                         end=row['DATE_FIN'],freq='D').values\n",
    "\n",
    "df_base['date'] = df_base.apply(getDatetimesArray, axis=1)\n",
    "\n",
    "df_base = df_base.explode('date')\n",
    "\n",
    "df_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzNs5j-Cc8g-"
   },
   "outputs": [],
   "source": [
    "df_base.sort_values(by=\"date\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vqvpzWYc_Q0"
   },
   "outputs": [],
   "source": [
    "# Second jeu de données : Contrat heures pleines - heures creuses\n",
    "df2 = pd.read_csv(\"TRV électricité inf36 HPHC_2012- S2 2023.csv\", sep = \";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7FCs1JGddwu"
   },
   "outputs": [],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLZb-Gxmdhhx"
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0A_zJSMAdni3"
   },
   "outputs": [],
   "source": [
    "# df2 # Création d'une colonne de prix total\n",
    "\n",
    "df2[\"PART_FIXE_TTC\"] = df2[\"PART_FIXE_TTC\"].apply(lambda x: x.replace(',','.').replace(',','.')).astype(\"float\")\n",
    "\n",
    "df2[\"PART_VARIABLE_HC_TTC\"] = df2[\"PART_VARIABLE_HC_TTC\"].apply(lambda x : x.replace(',','.').replace(',','.')).astype(\"float\")\n",
    "\n",
    "df2[\"PART_VARIABLE_HP_TTC\"] = df2[\"PART_VARIABLE_HP_TTC\"].apply(lambda x : x.replace(',','.').replace(',','.')).astype(\"float\")\n",
    "\n",
    "df2[\"prix_HC_ttc\"] = df2[\"PART_FIXE_TTC\"] + df2[\"PART_VARIABLE_HC_TTC\"]\n",
    "\n",
    "df2[\"prix_HP_ttc\"] = df2[\"PART_FIXE_TTC\"] + df2[\"PART_VARIABLE_HP_TTC\"]\n",
    "\n",
    "df2[\"prix_HC_HP_moy_ttc\"] = (df2[\"prix_HC_ttc\"] + df2[\"prix_HP_ttc\"])/2\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWvCjw_rdpt_"
   },
   "outputs": [],
   "source": [
    "# Regroupement par tarif par date et calcul du prix hc-hp moyen indépendamment de la puissance souscrite\n",
    "df2_hc_hp = df2.groupby([\"DATE_DEBUT\",\"DATE_FIN\"], as_index = False).agg({\"prix_HC_HP_moy_ttc\" : \"mean\"})\n",
    "\n",
    "df2_hc_hp[\"annee\"]= df2_hc_hp[\"DATE_FIN\"].str[6:].astype(\"int\")\n",
    "\n",
    "df2_hc_hp[\"mois\"] = df2_hc_hp[\"DATE_FIN\"].str[3:5].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fStX7BFtdx_F"
   },
   "outputs": [],
   "source": [
    "df2_hc_hp.sort_values([\"annee\"], ascending=[True]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTLWUkInd44y"
   },
   "outputs": [],
   "source": [
    "df2_hc_hp[\"DATE_DEBUT\"] = pd.to_datetime(df2_hc_hp[\"DATE_DEBUT\"], format='%d/%m/%Y')\n",
    "\n",
    "df2_hc_hp[\"DATE_FIN\"] = pd.to_datetime(df2_hc_hp[\"DATE_FIN\"], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDWROqTVeBVM"
   },
   "outputs": [],
   "source": [
    "df2_hc_hp = df2_hc_hp.dropna(subset=[\"DATE_FIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NevqDdLeFSN"
   },
   "outputs": [],
   "source": [
    "# Création d'un tarif par jour\n",
    "df2_hc_hp['date'] = df2_hc_hp.apply(getDatetimesArray, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6j7yf5NNeO7R"
   },
   "outputs": [],
   "source": [
    "df2_hc_hp = df2_hc_hp.explode('date')\n",
    "\n",
    "df2_hc_hp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9dzGDB-eP9D"
   },
   "outputs": [],
   "source": [
    "df2_hc_hp.sort_values(by=\"date\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyjKNlWr2BeP"
   },
   "outputs": [],
   "source": [
    "# Création d'un dataframe fusionné avec les deux colonnes de prix\n",
    "df_prix = df_base.merge(df2_hc_hp, how = \"left\", on=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdY7G63j2IQ4"
   },
   "outputs": [],
   "source": [
    "cols = [\"DATE_DEBUT_x\",\"DATE_FIN_x\",\"annee_x\",\"mois_x\",\"DATE_DEBUT_y\",\"DATE_FIN_y\",\"annee_y\",\"mois_y\"]\n",
    "\n",
    "df_prix = df_prix.drop(columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLgby68f2NLJ"
   },
   "outputs": [],
   "source": [
    "df_prix = df_prix[df_prix[\"date\"]> \"2012-12-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtSk2VKk2QrX"
   },
   "outputs": [],
   "source": [
    "df_prix = df_prix[df_prix[\"date\"]< \"2021-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20r8kOoX2RUT"
   },
   "outputs": [],
   "source": [
    "df_prix.sort_values([\"date\"], ascending=[False]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yn-ixdEP5GTg"
   },
   "outputs": [],
   "source": [
    "# Fusion avec df consolidé\n",
    "df_jour_temp_indispo_prix = df_jour_temp_indispo.merge(right=df_prix, how='left',left_on=['datetime'], right_on=['date'])\n",
    "df_jour_temp_indispo_prix = df_jour_temp_indispo_prix.drop(\"date\", axis=1)\n",
    "df_jour_temp_indispo_prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_jour_temp_indispo_prix[df_jour_temp_indispo_prix.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout de l'indication 'jour_off' si le jour est férié ou dimanche\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jf_df = pd.read_csv(\"jours_feries_metropole.csv\", parse_dates=['date'])\n",
    "jf_list = jf_df.date.dt.strftime('%Y-%m-%d').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_jour_temp_indispo_prix['jour_off'] = df_jour_temp_indispo_prix['datetime'].dt.weekday == 6 |  df_jour_temp_indispo_prix['datetime'].dt.strftime('%Y-%m-%d').isin(jf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_jour_temp_indispo_prix[df_jour_temp_indispo_prix['jour_off']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_jour_temp_indispo_prix[df_jour_temp_indispo_prix.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe définitif pour les modélisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJLLpzmP3JrZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creation d'un fichier csv contenant le dataframe préparé\n",
    "df_jour_temp_indispo_prix.to_csv(\"eco2mix-prepare-temperatures_indispo_prix.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df_jour_temp_indispo_prix\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation Random Forest, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = df.drop('consommation', axis=1)\n",
    "X = X.drop('datetime', axis=1)\n",
    "X = X.drop('region', axis=1)\n",
    "X = X.drop('code_region', axis=1)\n",
    "y = df['consommation']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "col = ['tco_thermique','tch_thermique','tco_nucléaire','tch_nucleaire','tco_eolien','tch_eolien','tco_solaire',\\\n",
    "        'tch_solaire','tco_hydraulique','tch_hydraulique','tco_bioenergies','tch_bioenergies','TMin','TMax','TMoy']\n",
    "col_train = X_train[col]\n",
    "col_test = X_test[col]\n",
    "\n",
    "# Remplacement des NANs des colonnes tco - tch et température par leurs médianes respectives\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "X_test.loc[:,col] = imputer.transform(col_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remplacement des NaN par 0 dans la colonne “defaut énergie moy jour”\n",
    "X_train.defaut_energie_moy_jour = X_train.defaut_energie_moy_jour.fillna(0)\n",
    "X_test.defaut_energie_moy_jour = X_test.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "# Standardisation des variables numériques\n",
    "col_num_train = X_train.iloc[:,1:]\n",
    "col_num_test = X_test.iloc[:,1:]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "col_num_train = scaler.fit_transform(col_num_train)\n",
    "col_num_test = scaler.fit(col_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor()\n",
    "rf.fit(X_train,y_train)\n",
    "print(rf.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = rf.score(X_test, y_test)\n",
    "print(f\"Score sur l'ensemble de test : {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_train, rf.predict(X_train), alpha=1)\n",
    "plt.title('Graphique de dispersion des vraies valeurs par rapport aux prédictions')\n",
    "plt.xlabel('Valeurs réelles')\n",
    "plt.ylabel('Prédictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "#Graphique\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Fonctionnalités')\n",
    "plt.title('Importance des fonctionnalités dans le modèle Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "feature_names = X_train[col].columns\n",
    "\n",
    "# Création et entraînement du modèle Gradient Boosting\n",
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(X_train[col], y_train)\n",
    "\n",
    "predictions_train_gb = gb.predict(X_train[col])\n",
    "\n",
    "r2_train_gb = gb.score(X_train[col], y_train)\n",
    "print(f\"R² sur les données d'entraînement (Gradient Boosting): {r2_train_gb}\")\n",
    "\n",
    "importances_gb = gb.feature_importances_\n",
    "indices_gb = np.argsort(importances_gb)[::-1]\n",
    "\n",
    "plt.figure(figsize=(11, 5))\n",
    "plt.bar(range(len(importances_gb)), importances_gb[indices_gb], align='center')\n",
    "plt.xticks(range(len(importances_gb)), feature_names[indices_gb], rotation=45)\n",
    "plt.title('Importance des caractéristiques (Gradient Boosting)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error sur l'ensemble de test : {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en variables explicatives (X) et la variable cible (y)\n",
    "X = df.drop('consommation', axis=1)\n",
    "X =X.drop('datetime', axis=1)\n",
    "X =X.drop('region', axis=1)\n",
    "X = X.drop('code_region', axis=1)\n",
    "y = df['consommation']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "col = ['saison','mois_sin','mois_cos','jour_sin','jour_cos','defaut_energie_moy_jour','prix_base_moyen_ttc',\\\n",
    "        'prix_HC_HP_moy_ttc','TMin','TMax','TMoy']\n",
    "col_train = X_train[col]\n",
    "col_test = X_test[col]\n",
    "\n",
    "# Remplacement des NANs des colonnes tco - tch et température par leurs médianes respectives\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "X_test.loc[:,col] = imputer.transform(col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation des variables numériques\n",
    "col_num_train = X_train.iloc[:,1:]\n",
    "col_num_test = X_test.iloc[:,1:]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "col_num_train = scaler.fit_transform(col_num_train)\n",
    "col_num_test = scaler.fit(col_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor()\n",
    "rf.fit(X_train[col],y_train)\n",
    "print(rf.score(X_train[col],y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_train[col])\n",
    "\n",
    "# Création d'un scatter plot avec Matplotlib\n",
    "plt.scatter(y_train, y_pred_rf, alpha=0.5)\n",
    "plt.xlabel('Vraies Valeurs')\n",
    "plt.ylabel('Prédictions')\n",
    "plt.title('Graphique de dispersion des vraies valeurs par rapport aux prédictions (Random Forest)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feature_names = X_train[col].columns\n",
    "\n",
    "# Tri des indices par ordre décroissant d'importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(importances)), importances[indices], align='center')\n",
    "plt.xticks(range(len(importances)), feature_names[indices], rotation=45)\n",
    "plt.title('Importance des caractéristiques')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Création et entraînement du modèle Gradient Boosting\n",
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(X_train[col], y_train)\n",
    "\n",
    "# Prédictions sur les données d'entraînement\n",
    "predictions_train_gb = gb.predict(X_train[col])\n",
    "\n",
    "r2_train_gb = gb.score(X_train[col], y_train)\n",
    "print(f\"R² sur les données d'entraînement (Gradient Boosting): {r2_train_gb}\")\n",
    "\n",
    "importances_gb = gb.feature_importances_\n",
    "indices_gb = np.argsort(importances_gb)[::-1]\n",
    "\n",
    "plt.figure(figsize=(11, 5))\n",
    "plt.bar(range(len(importances_gb)), importances_gb[indices_gb], align='center')\n",
    "plt.xticks(range(len(importances_gb)), feature_names[indices_gb], rotation=45)\n",
    "plt.title('Importance des caractéristiques (Gradient Boosting)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_gb = gb.predict(X_test[col])\n",
    "\n",
    "mse_test_gb = mean_squared_error(y_test, predictions_test_gb)\n",
    "\n",
    "print(f\"Mean Squared Error sur l'ensemble de test (Gradient Boosting): {mse_test_gb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_jour_temp_indispo_prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en variables explicatives (X) et la variable cible (y)\n",
    "X = df.drop('consommation', axis=1)\n",
    "X =X.drop('datetime', axis=1)\n",
    "X =X.drop('region', axis=1)\n",
    "X = X.drop('code_region', axis=1)\n",
    "y = df['consommation']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "col = ['saison','defaut_energie_moy_jour','prix_base_moyen_ttc',\\\n",
    "        'prix_HC_HP_moy_ttc','TMin','TMax','TMoy']\n",
    "col_train = X_train[col]\n",
    "col_test = X_test[col]\n",
    "\n",
    "# Remplacement des NANs des colonnes tco - tch et température par leurs médianes respectives\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "X_test.loc[:,col] = imputer.transform(col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement des NANs par 0\n",
    "X_train.loc[:, col] = col_train.fillna(0)\n",
    "X_test.loc[:, col] = col_test.fillna(0)\n",
    "\n",
    "# Standardisation des variables numériques\n",
    "col_num_train = X_train.iloc[:,1:]\n",
    "col_num_test = X_test.iloc[:,1:]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "col_num_train = scaler.fit_transform(col_num_train)\n",
    "col_num_test = scaler.fit(col_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor()\n",
    "rf.fit(X_train[col],y_train)\n",
    "print(rf.score(X_train[col],y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_train[col])\n",
    "result_rf_df = pd.DataFrame({'Vraies Valeurs': y_train, 'Prédictions': y_pred_rf})\n",
    "\n",
    "plt.scatter(result_rf_df['Vraies Valeurs'], result_rf_df['Prédictions'], alpha=0.5)\n",
    "plt.xlabel('Vraies Valeurs')\n",
    "plt.ylabel('Prédictions')\n",
    "plt.title('Graphique de dispersion des vraies valeurs par rapport aux prédictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feature_names = X_train[col].columns\n",
    "\n",
    "# Tri des indices par ordre décroissant d'importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(importances)), importances[indices], align='center')\n",
    "plt.xticks(range(len(importances)), feature_names[indices], rotation=45)\n",
    "plt.title('Importance des caractéristiques')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création et entraînement du modèle Gradient Boosting\n",
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(X_train[col], y_train)\n",
    "\n",
    "# Prédictions sur les données d'entraînement\n",
    "predictions_train_gb = gb.predict(X_train[col])\n",
    "\n",
    "r2_train_gb = gb.score(X_train[col], y_train)\n",
    "print(f\"R² sur les données d'entraînement (Gradient Boosting): {r2_train_gb}\")\n",
    "\n",
    "importances_gb = gb.feature_importances_\n",
    "indices_gb = np.argsort(importances_gb)[::-1]\n",
    "\n",
    "plt.figure(figsize=(11, 5))\n",
    "plt.bar(range(len(importances_gb)), importances_gb[indices_gb], align='center')\n",
    "plt.xticks(range(len(importances_gb)), feature_names[indices_gb], rotation=45)\n",
    "plt.title('Importance des caractéristiques (Gradient Boosting)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_gb = gb.predict(X_test[col])\n",
    "\n",
    "mse_test_gb = mean_squared_error(y_test, predictions_test_gb)\n",
    "\n",
    "print(f\"Mean Squared Error sur l'ensemble de test (Gradient Boosting): {mse_test_gb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisations GradientBoostingRegressor, Metrics, Ridge et Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = df_jour_temp_indispo_prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd = dfe[dfe.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identification des NaN\n",
    "dfe[~dfe[\"defaut_energie_moy_jour\"].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration des modalités des variables catégorielles\n",
    "\n",
    "print(dfe[[\"region\",\"code_region\"]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'information entre le code région et la région est redondante, je supprime code région du dfe\n",
    "dfe = dfe.drop(\"code_region\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification de la variable cible et des variables explicatives\n",
    "target = dfe[\"consommation\"]\n",
    "\n",
    "feats = dfe.drop(\"consommation\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Séparation du jeu de données en jeu d'entraînement et jeu de test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"tco_thermique\",\"tch_thermique\",\"tco_nucléaire\",\"tch_nucleaire\",\"tco_eolien\",\"tch_eolien\",\"tco_solaire\",\\\n",
    "        \"tch_solaire\",\"tco_hydraulique\",\"tch_hydraulique\",\"tco_bioenergies\",\"tch_bioenergies\",\"TMin\",\"TMax\",\"TMoy\"]\n",
    "\n",
    "col_train = X_train[col]\n",
    "\n",
    "col_test = X_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement des NANs des colonnes tco - tch et température par leurs médianes respectives\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"median\")\n",
    "\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "\n",
    "X_test.loc[:,col] = imputer.transform(col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remplacement des NaN par 0 dans la colonne \"defaut énergie moy jour\"\n",
    "\n",
    "X_train.defaut_energie_moy_jour = X_train.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "X_test.defaut_energie_moy_jour = X_test.defaut_energie_moy_jour.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation des variables numériques soit colonnes 3 à 30\n",
    "\n",
    "col_num_train = X_train.iloc[:,2:]\n",
    "\n",
    "col_num_test = X_test.iloc[:,2:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "col_num_train = scaler.fit_transform(col_num_train)\n",
    "\n",
    "col_num_test = scaler.fit(col_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage de la variable explicative region - pandas.get_dummies\n",
    "\n",
    "X_train = pd.get_dummies(X_train)\n",
    "\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage de la variable datetime\n",
    "import datetime as dt\n",
    "X_train['datetime']=X_train['datetime'].map(dt.datetime.toordinal)\n",
    "\n",
    "X_test['datetime']=X_test['datetime'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Première modélisation : GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state = 0)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score train :\",reg.score(X_train,y_train))\n",
    "\n",
    "print(\"Score test :\",reg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher représentation de pred test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.scatter(y_pred, y_test, c=\"green\")\n",
    "\n",
    "plt.plot((y_test.min(),y_test.max()),(y_test.min(),y_test.max()), color = \"red\")\n",
    "\n",
    "plt.xlabel(\"Prédiction\")\n",
    "plt.ylabel(\"Vraie valeur\")\n",
    "\n",
    "plt.title(\"Gradient Boosting Regressor pour la prédiction de la consommation\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les feature importances\n",
    "\n",
    "print(reg.feature_importances_)\n",
    "\n",
    "feat_imp = pd.DataFrame(reg.feature_importances_, index = X_train.columns, columns = [\"Importance\"])\n",
    "\n",
    "feat_imp.sort_values(by = \"Importance\", ascending = False)\n",
    "\n",
    "feat_imp.plot(kind = \"bar\", figsize=(8,8))\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seconde modélisation : Suppression de la variable production nette\n",
    "\n",
    "dfe = dfe.drop(\"production_nette\", axis = 1)\n",
    "\n",
    "target = dfe[\"consommation\"]\n",
    "\n",
    "feats = dfe.drop(\"consommation\", axis =1)\n",
    "\n",
    "#Séparation du jeu de données en jeu d'entraînement et jeu de test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size = 0.2)\n",
    "\n",
    "col = [\"tco_thermique\",\"tch_thermique\",\"tco_nucléaire\",\"tch_nucleaire\",\"tco_eolien\",\"tch_eolien\",\"tco_solaire\",\\\n",
    "        \"tch_solaire\",\"tco_hydraulique\",\"tch_hydraulique\",\"tco_bioenergies\",\"tch_bioenergies\",\"TMin\",\"TMax\",\"TMoy\"]\n",
    "\n",
    "col_train = X_train[col]\n",
    "\n",
    "col_test = X_test[col]\n",
    "\n",
    "# Remplacement des NANs des colonnes tco - tch et température par leurs médianes respectives\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"median\")\n",
    "\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "\n",
    "X_test.loc[:,col] = imputer.transform(col_test)\n",
    "\n",
    "#Remplacement des NaN par 0 dans la colonne \"defaut énergie moy jour\"\n",
    "\n",
    "X_train.defaut_energie_moy_jour = X_train.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "X_test.defaut_energie_moy_jour = X_test.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "# Standardisation des variables numériques soit colonnes 3 à 30\n",
    "\n",
    "col_num_train = X_train.iloc[:,2:]\n",
    "\n",
    "col_num_test = X_test.iloc[:,2:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "col_num_train = scaler.fit_transform(col_num_train)\n",
    "\n",
    "col_num_test = scaler.fit(col_num_test)\n",
    "\n",
    "# Encodage de la variable explicative region - pandas.get_dummies\n",
    "\n",
    "X_train = pd.get_dummies(X_train)\n",
    "\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Encodage de la variable datetime\n",
    "import datetime as dt\n",
    "X_train['datetime']=X_train['datetime'].map(dt.datetime.toordinal)\n",
    "\n",
    "X_test['datetime']=X_test['datetime'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seconde modélisation : GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state = 0)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"Score train :\",reg.score(X_train,y_train))\n",
    "\n",
    "print(\"Score test :\",reg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher représentation de pred test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.scatter(y_pred, y_test, c=\"green\")\n",
    "\n",
    "plt.plot((y_test.min(),y_test.max()),(y_test.min(),y_test.max()), color = \"red\")\n",
    "\n",
    "plt.xlabel(\"Prédiction\")\n",
    "plt.ylabel(\"Vraie valeur\")\n",
    "\n",
    "plt.title(\"Gradient Boosting Regressor pour la prédiction de la consommation\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les feature importances\n",
    "\n",
    "print(reg.feature_importances_)\n",
    "\n",
    "feat_imp = pd.DataFrame(reg.feature_importances_, index = X_train.columns, columns = [\"Importance\"])\n",
    "\n",
    "feat_imp.sort_values(by = \"Importance\", ascending = False)\n",
    "\n",
    "feat_imp.plot(kind = \"bar\", figsize=(8,8))\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troisième modélisation : Suppression des variables explicatives liées à la production \n",
    "\n",
    "target = dfe[\"consommation\"]\n",
    "\n",
    "feats = dfe[[\"datetime\",\"annee\",\"num_mois\",\"saison\",\"mois_sin\",\"mois_cos\",\"jour_sin\",\"jour_cos\",\"TMin\",\"TMax\",\"TMoy\",\n",
    "             \"defaut_energie_moy_jour\",\"prix_base_moyen_ttc\",\"prix_HC_HP_moy_ttc\",\"jour_off\"]]\n",
    "\n",
    "#Séparation du jeu de données en jeu d'entraînement et jeu de test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size = 0.2)\n",
    "\n",
    "col = [\"TMin\",\"TMax\",\"TMoy\"]\n",
    "\n",
    "col_train = X_train[col]\n",
    "\n",
    "col_test = X_test[col]\n",
    "\n",
    "# Remplacement des NANs des colonnes température par leurs médianes respectives\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"median\")\n",
    "\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "\n",
    "X_test.loc[:,col] = imputer.transform(col_test)\n",
    "\n",
    "#Remplacement des NaN par 0 dans la colonne \"defaut énergie moy jour\"\n",
    "\n",
    "X_train.defaut_energie_moy_jour = X_train.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "X_test.defaut_energie_moy_jour = X_test.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation des variables numériques \n",
    "\n",
    "col_num_train = X_train.iloc[:,1:14]\n",
    "\n",
    "col_num_test = X_test.iloc[:,1:14]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "col_num_train = scaler.fit_transform(col_num_train)\n",
    "\n",
    "col_num_test = scaler.fit(col_num_test)\n",
    "\n",
    "# Encodage de la variable datetime\n",
    "import datetime as dt\n",
    "X_train['datetime']=X_train['datetime'].map(dt.datetime.toordinal)\n",
    "\n",
    "X_test['datetime']=X_test['datetime'].map(dt.datetime.toordinal)\n",
    "\n",
    "\n",
    "# Troisième modélisation : GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state = 0)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"Score train :\",reg.score(X_train,y_train))\n",
    "\n",
    "print(\"Score test :\",reg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher représentation de pred test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.scatter(y_pred, y_test, c=\"green\")\n",
    "\n",
    "plt.plot((y_test.min(),y_test.max()),(y_test.min(),y_test.max()), color = \"red\")\n",
    "\n",
    "plt.xlabel(\"Prédiction\")\n",
    "plt.ylabel(\"Vraie valeur\")\n",
    "\n",
    "plt.title(\"Gradient Boosting Regressor pour la prédiction de la consommation\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les feature importances\n",
    "\n",
    "print(reg.feature_importances_)\n",
    "\n",
    "feat_imp = pd.DataFrame(reg.feature_importances_, index = X_train.columns, columns = [\"Importance\"])\n",
    "\n",
    "feat_imp.sort_values(by = \"Importance\", ascending = False)\n",
    "\n",
    "feat_imp.plot(kind = \"bar\", figsize=(8,8))\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dernière modélisation avec les variables explicatives : defaut_energie_moy_jour, mois_cos, TMoy, TMax\n",
    "\n",
    "target = dfe[\"consommation\"]\n",
    "\n",
    "feats = dfe[[\"defaut_energie_moy_jour\",\"mois_cos\",\"TMax\",\"TMoy\"]]\n",
    "\n",
    "#Séparation du jeu de données en jeu d'entraînement et jeu de test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size = 0.2)\n",
    "\n",
    "col = [\"TMax\",\"TMoy\"]\n",
    "\n",
    "col_train = X_train[col]\n",
    "\n",
    "col_test = X_test[col]\n",
    "\n",
    "# Remplacement des NANs des colonnes température par leurs médianes respectives\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"median\")\n",
    "\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "\n",
    "X_test.loc[:,col] = imputer.transform(col_test)\n",
    "\n",
    "#Remplacement des NaN par 0 dans la colonne \"defaut énergie moy jour\"\n",
    "\n",
    "X_train.defaut_energie_moy_jour = X_train.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "X_test.defaut_energie_moy_jour = X_test.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "\n",
    "# Standardisation des variables numériques soit colonnes 1 à 3\n",
    "\n",
    "col_num_train = X_train.iloc[:,1:]\n",
    "\n",
    "col_num_test = X_test.iloc[:,1:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "col_num_train = scaler.fit_transform(col_num_train)\n",
    "\n",
    "col_num_test = scaler.fit(col_num_test)\n",
    "\n",
    "\n",
    "# Troisième modélisation : GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state = 0)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"Score train :\",reg.score(X_train,y_train))\n",
    "\n",
    "print(\"Score test :\",reg.score(X_test,y_test))\n",
    "\n",
    "# Afficher représentation de pred test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.scatter(y_pred, y_test, c=\"green\")\n",
    "\n",
    "plt.plot((y_test.min(),y_test.max()),(y_test.min(),y_test.max()), color = \"red\")\n",
    "\n",
    "plt.xlabel(\"Prédiction\")\n",
    "plt.ylabel(\"Vraie valeur\")\n",
    "\n",
    "plt.title(\"Gradient Boosting Regressor pour la prédiction de la consommation\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des métriques en comparant 3 modèles, Random Forest, GradientBoosting Regressor et Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Score train:\",rf.score(X_train,y_train))\n",
    "\n",
    "print(\"Score test:\", rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "pred_train_rf = rf.predict(X_train)\n",
    "\n",
    "mae_rf_train = mean_absolute_error(y_train, pred_train_rf)\n",
    "\n",
    "mse_rf_train = mean_squared_error(y_train, pred_train_rf)\n",
    "\n",
    "rmse_rf_train = mean_squared_error(y_train, pred_train_rf, squared = False)\n",
    "\n",
    "mae_rf_test = mean_absolute_error(y_test, pred_rf)\n",
    "\n",
    "mse_rf_test = mean_squared_error(y_test, pred_rf)\n",
    "\n",
    "rmse_rf_test = mean_squared_error(y_test, pred_rf, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des 3 métriques\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg_dt = DecisionTreeRegressor()\n",
    "\n",
    "reg_dt.fit(X_train, y_train)\n",
    "\n",
    "pred_dt = reg_dt.predict(X_test)\n",
    "\n",
    "pred_train_dt = reg_dt.predict(X_train)\n",
    "\n",
    "mae_dt_train = mean_absolute_error(y_train, pred_train_dt)\n",
    "\n",
    "mse_dt_train = mean_squared_error(y_train, pred_train_dt)\n",
    "\n",
    "rmse_dt_train = mean_squared_error(y_train, pred_train_dt, squared = False)\n",
    "\n",
    "mae_dt_test = mean_absolute_error(y_test, pred_dt)\n",
    "\n",
    "mse_dt_test = mean_squared_error(y_test, pred_dt)\n",
    "\n",
    "rmse_dt_test = mean_squared_error(y_test, pred_dt, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score train:\",reg_dt.score(X_train,y_train))\n",
    "\n",
    "print(\"Score test:\", reg_dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques de GBoostR :\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "pred_train_reg = reg.predict(X_train)\n",
    "\n",
    "mae_reg_train = mean_absolute_error(y_train, pred_train_reg)\n",
    "\n",
    "mse_reg_train = mean_squared_error(y_train, pred_train_reg)\n",
    "\n",
    "rmse_reg_train = mean_squared_error(y_train, pred_train_reg, squared = False)\n",
    "\n",
    "mae_reg_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_reg_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse_reg_test = mean_squared_error(y_test, y_pred, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un df des métriques\n",
    "\n",
    "data = {'MAE train':[mae_reg_train,mae_dt_train,mae_rf_train],\n",
    "       'MAE test' :[mae_reg_test,mae_dt_test,mae_rf_test],\n",
    "       'MSE train' :[mse_reg_train,mse_dt_train,mse_rf_train],\n",
    "       'MSE test' :[mse_reg_test,mse_dt_test,mse_rf_test],\n",
    "       'RMSE train':[rmse_reg_train,rmse_dt_train,rmse_rf_train],\n",
    "       'RMSE test':[rmse_reg_test,rmse_dt_test,rmse_rf_test]}\n",
    "\n",
    "df = pd.DataFrame(data, index = ['GradientBoostRegression','DecisionTree','RandomForest'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dernière modélisation avec les variables explicatives : defaut_energie_moy_jour, mois_cos, TMoy, TMax, \n",
    "#échanges physiques\n",
    "\n",
    "target = dfe[\"consommation\"]\n",
    "\n",
    "feats = dfe[[\"defaut_energie_moy_jour\",\"mois_cos\",\"TMax\",\"TMoy\",\"ech.physiques\" ]]\n",
    "\n",
    "#Séparation du jeu de données en jeu d'entraînement et jeu de test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size = 0.2)\n",
    "\n",
    "col = [\"TMax\",\"TMoy\"]\n",
    "\n",
    "col_train = X_train[col]\n",
    "\n",
    "col_test = X_test[col]\n",
    "\n",
    "# Remplacement des NANs des colonnes température par leurs médianes respectives\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"median\")\n",
    "\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "\n",
    "X_test.loc[:,col] = imputer.transform(col_test)\n",
    "\n",
    "#Remplacement des NaN par 0 dans la colonne \"defaut énergie moy jour\"\n",
    "\n",
    "X_train.defaut_energie_moy_jour = X_train.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "X_test.defaut_energie_moy_jour = X_test.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "\n",
    "# Standardisation des variables numériques soit colonnes 1 à 3\n",
    "\n",
    "col_num_train = X_train.iloc[:,1:]\n",
    "\n",
    "col_num_test = X_test.iloc[:,1:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "col_num_train = scaler.fit_transform(col_num_train)\n",
    "\n",
    "col_num_test = scaler.fit(col_num_test)\n",
    "\n",
    "\n",
    "# Troisième modélisation : GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state = 0)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"Score train :\",reg.score(X_train,y_train))\n",
    "\n",
    "print(\"Score test :\",reg.score(X_test,y_test))\n",
    "\n",
    "# Afficher représentation de pred test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.scatter(y_pred, y_test, c=\"green\")\n",
    "\n",
    "plt.plot((y_test.min(),y_test.max()),(y_test.min(),y_test.max()), color = \"red\")\n",
    "\n",
    "plt.xlabel(\"Prédiction\")\n",
    "plt.ylabel(\"Vraie valeur\")\n",
    "\n",
    "plt.title(\"Gradient Boosting Regressor pour la prédiction de la consommation\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Score train:\",rf.score(X_train,y_train))\n",
    "\n",
    "print(\"Score test:\", rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "pred_train_rf = rf.predict(X_train)\n",
    "\n",
    "mae_rf_train = mean_absolute_error(y_train, pred_train_rf)\n",
    "\n",
    "mse_rf_train = mean_squared_error(y_train, pred_train_rf)\n",
    "\n",
    "rmse_rf_train = mean_squared_error(y_train, pred_train_rf, squared = False)\n",
    "\n",
    "mae_rf_test = mean_absolute_error(y_test, pred_rf)\n",
    "\n",
    "mse_rf_test = mean_squared_error(y_test, pred_rf)\n",
    "\n",
    "rmse_rf_test = mean_squared_error(y_test, pred_rf, squared = False)\n",
    "\n",
    "# Calcul des 3 métriques\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg_dt = DecisionTreeRegressor()\n",
    "\n",
    "reg_dt.fit(X_train, y_train)\n",
    "\n",
    "pred_dt = reg_dt.predict(X_test)\n",
    "\n",
    "pred_train_dt = reg_dt.predict(X_train)\n",
    "\n",
    "mae_dt_train = mean_absolute_error(y_train, pred_train_dt)\n",
    "\n",
    "mse_dt_train = mean_squared_error(y_train, pred_train_dt)\n",
    "\n",
    "rmse_dt_train = mean_squared_error(y_train, pred_train_dt, squared = False)\n",
    "\n",
    "mae_dt_test = mean_absolute_error(y_test, pred_dt)\n",
    "\n",
    "mse_dt_test = mean_squared_error(y_test, pred_dt)\n",
    "\n",
    "rmse_dt_test = mean_squared_error(y_test, pred_dt, squared = False)\n",
    "\n",
    "# Affichage des scores du modèle\n",
    "print(\"Score train:\",reg_dt.score(X_train,y_train))\n",
    "\n",
    "print(\"Score test:\", reg_dt.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Calcul des métriques de GBoostR :\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "pred_train_reg = reg.predict(X_train)\n",
    "\n",
    "mae_reg_train = mean_absolute_error(y_train, pred_train_reg)\n",
    "\n",
    "mse_reg_train = mean_squared_error(y_train, pred_train_reg)\n",
    "\n",
    "rmse_reg_train = mean_squared_error(y_train, pred_train_reg, squared = False)\n",
    "\n",
    "mae_reg_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse_reg_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse_reg_test = mean_squared_error(y_test, y_pred, squared = False)\n",
    "\n",
    "\n",
    "# Création d'un df des métriques\n",
    "\n",
    "data = {'MAE train':[mae_reg_train,mae_dt_train,mae_rf_train],\n",
    "       'MAE test' :[mae_reg_test,mae_dt_test,mae_rf_test],\n",
    "       'MSE train' :[mse_reg_train,mse_dt_train,mse_rf_train],\n",
    "       'MSE test' :[mse_reg_test,mse_dt_test,mse_rf_test],\n",
    "       'RMSE train':[rmse_reg_train,rmse_dt_train,rmse_rf_train],\n",
    "       'RMSE test':[rmse_reg_test,rmse_dt_test,rmse_rf_test]}\n",
    "\n",
    "df = pd.DataFrame(data, index = ['GradientBoostRegression','DecisionTree','RandomForest'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisations Ridge et Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dfe[\"consommation\"]\n",
    "\n",
    "feats = dfe[[\"datetime\",\"annee\",\"num_mois\",\"saison\",\"mois_sin\",\"mois_cos\",\"jour_sin\",\"jour_cos\",\"TMin\",\"TMax\",\"TMoy\",\n",
    "             \"defaut_energie_moy_jour\",\"prix_base_moyen_ttc\",\"prix_HC_HP_moy_ttc\",\"jour_off\"]]\n",
    "\n",
    "#Séparation du jeu de données en jeu d'entraînement et jeu de test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size = 0.2)\n",
    "\n",
    "col = [\"TMin\",\"TMax\",\"TMoy\"]\n",
    "\n",
    "col_train = X_train[col]\n",
    "\n",
    "col_test = X_test[col]\n",
    "\n",
    "# Remplacement des NANs des colonnes température par leurs médianes respectives\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"median\")\n",
    "\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "\n",
    "X_test.loc[:,col] = imputer.transform(col_test)\n",
    "\n",
    "#Remplacement des NaN par 0 dans la colonne \"defaut énergie moy jour\"\n",
    "\n",
    "X_train.defaut_energie_moy_jour = X_train.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "X_test.defaut_energie_moy_jour = X_test.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "# Remplacement des NANs des colonnes température par leurs médianes respectives\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"median\")\n",
    "\n",
    "X_train.loc[:,col] = imputer.fit_transform(col_train)\n",
    "\n",
    "X_test.loc[:,col] = imputer.transform(col_test)\n",
    "\n",
    "#Remplacement des NaN par 0 dans la colonne \"defaut énergie moy jour\"\n",
    "\n",
    "X_train.defaut_energie_moy_jour = X_train.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "X_test.defaut_energie_moy_jour = X_test.defaut_energie_moy_jour.fillna(0)\n",
    "\n",
    "\n",
    "# Standardisation des variables numériques \n",
    "\n",
    "col_num_train = X_train.iloc[:,1:]\n",
    "\n",
    "col_num_test = X_test.iloc[:,1:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "col_num_train = scaler.fit_transform(col_num_train)\n",
    "\n",
    "col_num_test = scaler.fit(col_num_test)\n",
    "\n",
    "\n",
    "# Encodage de la variable datetime\n",
    "import datetime as dt\n",
    "X_train['datetime']=X_train['datetime'].map(dt.datetime.toordinal)\n",
    "\n",
    "X_test['datetime']=X_test['datetime'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge_reg = RidgeCV(alphas= (0.001, 0.01, 0.1, 0.3, 0.7, 1, 10, 50, 100))\n",
    "ridge_reg.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('alpha sélectionné par c-v :', ridge_reg.alpha_)\n",
    "print('score train :', ridge_reg.score(X_train, y_train))\n",
    "print('score test :', ridge_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred_train = ridge_reg.predict(X_train)\n",
    "ridge_pred_test = ridge_reg.predict(X_test)\n",
    "\n",
    "print('mse train :', mean_squared_error(ridge_pred_train, y_train))\n",
    "print('mse test :', mean_squared_error(ridge_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_r = Lasso(alpha=1)\n",
    "\n",
    "lasso_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_r.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = Lasso(alpha=0.1)\n",
    "\n",
    "lasso_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef = lasso_reg.coef_\n",
    "\n",
    "plt.plot(range(len(feats.columns)), lasso_coef)\n",
    "plt.xticks(range(len(feats.columns)), feats.columns.values, rotation=70);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('score train :', lasso_reg.score(X_train, y_train))\n",
    "print('score test :', lasso_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pred_train = lasso_reg.predict(X_train)\n",
    "lasso_pred_test = lasso_reg.predict(X_test)\n",
    "\n",
    "print('mse train :', mean_squared_error(lasso_pred_train, y_train))\n",
    "print('mse test :', mean_squared_error(lasso_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lasso_path\n",
    "\n",
    "mes_alphas = (0.001, 0.01, 0.02, 0.025, 0.05, 0.1, 0.25, 0.5, 0.8, 1.0)\n",
    "\n",
    "alpha_path, coefs_lasso, _ = lasso_path(X_train, y_train, alphas=mes_alphas)\n",
    "\n",
    "coefs_lasso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for i in range(coefs_lasso.shape[0]):\n",
    "    plt.plot(alpha_path, coefs_lasso[i,:], '--')\n",
    "\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso path')\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "model_lasso = LassoCV(cv=10).fit(X_train, y_train)\n",
    "\n",
    "alphas = model_lasso.alphas_\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.plot(alphas, model_lasso.mse_path_, ':')\n",
    "plt.plot(alphas, model_lasso.mse_path_.mean(axis=1), 'k', label='Moyenne', linewidth=2)\n",
    "\n",
    "plt.axvline(model_lasso.alpha_, linestyle='--', color='k', label='alpha : estimation CV')\n",
    "\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean square error')\n",
    "plt.title('Mean square error pour chaque échantillon')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model_lasso.predict(X_test)\n",
    "\n",
    "print('score test :', model_lasso.score(X_test, y_test))\n",
    "print('mse test :', mean_squared_error(pred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
